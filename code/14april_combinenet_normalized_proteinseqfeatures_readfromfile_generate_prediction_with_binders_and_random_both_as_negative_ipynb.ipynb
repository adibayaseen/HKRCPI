{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adibayaseen/HKRCPI/blob/main/code/14april_combinenet_normalized_proteinseqfeatures_readfromfile_generate_prediction_with_binders_and_random_both_as_negative_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5zy8pv8_EQa"
      },
      "source": [
        "**Set the Runtime->Change Runtime Type to GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLKfwNHlwnSE"
      },
      "source": [
        "# Protein 3d structure assessment with graph neural networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_3U6PueCCgv",
        "outputId": "8c6a1de6-6bf5-4bba-8d81-9399f3170f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'PPI-Inhibitors': No such file or directory\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting biopython\n",
            "  Downloading biopython-1.81-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from biopython) (1.22.4)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.81\n",
            "Cloning into 'PPI-Inhibitors'...\n",
            "remote: Enumerating objects: 367, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 367 (delta 74), reused 95 (delta 48), pack-reused 221\u001b[K\n",
            "Receiving objects: 100% (367/367), 9.59 MiB | 12.40 MiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n"
          ]
        }
      ],
      "source": [
        "#!rm -r Data\n",
        "!rm -r PPI-Inhibitors\n",
        "!pip install biopython\n",
        "!git clone https://github.com/adibayaseen/PPI-Inhibitors\n",
        "#!pip install py3Dmol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE6yIRsQ7C5Y",
        "outputId": "101cbd76-ec56-4d65-d9d4-fb23b0739ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2022.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rdkit) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from rdkit) (8.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2022.9.5\n",
            "/bin/bash: conda: command not found\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!conda install -c bioconda biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzqYHeZuel_M",
        "outputId": "29b9b76a-6875-431a-c77e-78e0bea1d095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (2.0.0+cu118)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7vZs3hPeTLk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "class IPPI_MLP_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IPPI_MLP_Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(2328, 1024)#4096)2328\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 100)\n",
        "        self.fc5 = nn.Linear( 100,1)\n",
        "    def forward(self,PFeatures,LigandFeatures):\n",
        "          PFeatures=torch.FloatTensor(PFeatures).cuda()\n",
        "          Cfeatures=torch.FloatTensor(LigandFeatures).cuda()#Compound_Net(LigandFeatures)\n",
        "          PC_Features=torch.hstack((PFeatures,Cfeatures))\n",
        "          x = torch.tanh(self.fc1(PC_Features))\n",
        "          #pdb.set_trace()\n",
        "          x = torch.tanh(self.fc2(x) )\n",
        "          x = torch.tanh(self.fc3(x) )\n",
        "          x = self.fc5(x) \n",
        "          return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1SQW8SMmjAl",
        "outputId": "570e3945-cc0d-4afd-f7e9-6575c4c5b157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15695/15695 [00:00<00:00, 148926.65it/s]\n",
            "<ipython-input-9-32f8c2d83265>:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  Alldata=np.array(Alldata)#Alldata=list (Allexamples.keys());\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Batch loss 0.13045402501056716\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Sequence based features\n",
        "\"\"\"\n",
        "from tqdm import tqdm as tqdm\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import auc,roc_auc_score,roc_curve,precision_score,recall_score,average_precision_score,precision_recall_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import normalize\n",
        "from torchmetrics.classification import BinaryHingeLoss\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    #path='D:/PhD/Inhibitor/InhibitorNewModel2022/'\n",
        "    #path='/content/drive/MyDrive/GNN-PPI-Inhibitor/'\n",
        "    githubpath='/content/PPI-Inhibitors/'\n",
        "    Ubench5InterfaceandSeq_dict=pickle.load(open(githubpath+'Features/NewUbench5InterfaceandSeq_dict.npy',\"rb\"))\n",
        "    Pos_seqandInterfaceF_dict=pickle.load(open(githubpath+'Features/Pos_seqandInterfaceF_dict.npy',\"rb\"))\n",
        "    Complex_AllFeatures_dict=dict( list (Pos_seqandInterfaceF_dict.items())+list (Ubench5InterfaceandSeq_dict.items())) \n",
        "    CompoundFingerprintFeaturesDict=pickle.load(open(githubpath+'Features/Compound_Fingerprint_Features_Dict.npy',\"rb\"))\n",
        "    Z = []; Yo = []; A = [];Yp=[];AUC_ROC_final=[];Precision_final=[];Recall_final=[];Avg_P_final=[];\n",
        "    with open(githubpath+'Data/WriteAllexamplesRandomBindersIdsAll_24JAN.txt') as f:\n",
        "    #with open(githubpath+'Data/WriteAllexamplesRandomBindersIdsAll_24JAN_Binary.txt') as f:\n",
        "        D = f.readlines()\n",
        "    Labels=[];Ligandnames=[];Complexs=[];TestPoscomplexes=[];Batchlosslist=[];\n",
        "    for d in tqdm(D):\n",
        "      if len(d.split())==4:\n",
        "          TestPoscomp,Complexname,Ligandname,label = d.split()\n",
        "      else:\n",
        "          TestPoscomp,Complexname,Ligandname,label = d.split()[0],d.split()[1],(' ').join(d.split()[2:-1]),d.split()[-1]\n",
        "      TestPoscomplexes.append(TestPoscomp),Ligandnames.append(Ligandname);Complexs.append(Complexname);Labels.append(float (label))\n",
        "    #########\n",
        "    Allexamples=dict (zip(zip(TestPoscomplexes,zip(Complexs,Ligandnames)),Labels))\n",
        "    Alldata=list (Allexamples.keys())\n",
        "    KK=[k[0].split('_')[0] for k in Alldata]\n",
        "    groups = pd.DataFrame(KK)\n",
        "    gkf = GroupKFold(n_splits=len(set (KK)))\n",
        "    ###########\n",
        "    AlltestExamples=[];Externallabels=[];ExternalscoresLOCO=[];covid19_Externallabels=[];covid19_ExternalscoresLOCO=[];Y_score=[];Y_t=[];classratio_dict={};\n",
        "    Complexs,Ligandnames, Labels=np.array(Complexs),np.array(Ligandnames),np.array(Labels)\n",
        "    for trainindex, testindex in gkf.split(KK, KK, groups=groups):\n",
        "        Alldata=np.array(Alldata)#Alldata=list (Allexamples.keys());\n",
        "        train,test=Alldata[trainindex],Alldata[testindex]\n",
        "        Ctr=[];Ptr=[];y_train=[];Ctrname=[];Ptrname=[];Xtr=[];G=[];\n",
        "        for t in train:\n",
        "            Ctrname.append(t[1][1]);Ctr.append(CompoundFingerprintFeaturesDict[t[1][1]]);\n",
        "            Ptrname.append( t[1][0]);Ptr.append( Complex_AllFeatures_dict[t[1][0]]);y_train.append(Allexamples[t[0],t[1]])\n",
        "        Pscaler = StandardScaler().fit(Ptr)\n",
        "        Cscaler = StandardScaler().fit(Ctr)\n",
        "        Ptr,Ctr = Pscaler.transform(Ptr), Cscaler.transform(Ctr)\n",
        "        Ptrdict=dict (zip(Ptrname,Ptr))\n",
        "        Ctrdict=dict (zip (Ctrname,Ctr))\n",
        "        ########33\n",
        "        Xtr=np.hstack((Ptr,Ctr))\n",
        "        G=dict(zip(zip(Ptrname,Ctrname),Xtr))\n",
        "        ###############\n",
        "        IPPI_Net = IPPI_MLP_Net().cuda()\n",
        "        #criterion = BinaryHingeLoss().cuda()\n",
        "        criterion = nn.MSELoss().cuda()\n",
        "        optimizer = optim.Adam(list (IPPI_Net.parameters()),lr=0.001,weight_decay=0.0)#0001)#0.69 for 1mer single layer#, weight_decay=0.01, betas=(0.9, 0.999))\n",
        "        y_train=torch.FloatTensor( y_train).cuda()\n",
        "        ################load classratio_dict\n",
        "        classratio_dict=pickle.load(open(githubpath+'Features/Classratio_dict.npy','rb'))\n",
        "        for epoch in range(200):\n",
        "          Batchloss=0\n",
        "          for n in range(len(train)):#int (len(train)/10)):\n",
        "            complexname,Ligandname=train[n][1]\n",
        "            output=IPPI_Net(Ptrdict[complexname],Ctrdict[Ligandname])\n",
        "            loss=criterion(output, y_train[n].reshape(1))\n",
        "            \"\"\"\n",
        "            if y_train[n]==1.0:\n",
        "              #print(train[n][0],classratio_dict[train[n][0]])\n",
        "              loss=classratio_dict[train[n][0]]*loss\n",
        "            \"\"\"\n",
        "            Batchloss=Batchloss+loss#.cpu().data.numpy()\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if Batchloss<0.015:\n",
        "              break;\n",
        "          Batchlosslist.append(Batchloss.cpu().data.numpy()/len(train))#int (len(train)/10))#\n",
        "          print(\"Epoch\",epoch,\"Batch loss\",Batchloss.cpu().data.numpy()/len(train))\n",
        "         \n",
        "        ######\n",
        "        plt.figure()\n",
        "        plt.plot(Batchlosslist)\n",
        "        plt.title('batchloss');plt.xlabel('epochs');plt.ylabel('loss');plt.grid();plt.legend();plt.show();\n",
        "        #Testing\n",
        "        Ctt=[];Ptt=[];y_test=[];Cttname=[];Pttname=[];\n",
        "        for t in test:\n",
        "            Cttname.append(t[1][1]);Ctt.append(CompoundFingerprintFeaturesDict[t[1][1]]);\n",
        "            Pttname.append( t[1][0]);Ptt.append( Complex_AllFeatures_dict[t[1][0]]);y_test.append(Allexamples[t[0],t[1]])\n",
        "        Ptt,Ctt = Pscaler.transform(Ptt), Cscaler.transform(Ctt)\n",
        "        Pttdict=dict (zip(Pttname,Ptt))\n",
        "        Cttdict=dict (zip (Cttname,Ctt))\n",
        "        #y_test=torch.FloatTensor( y_test).cuda()\n",
        "        for nt in range(len(test)):\n",
        "          complexname,Ligandname =test[nt][1]\n",
        "          test_score=IPPI_Net(Pttdict[complexname],Cttdict[Ligandname])\n",
        "          Y_score.extend(test_score.cpu().data.numpy())\n",
        "          Y_t.append(y_test[nt])#.cpu().data.numpy())\n",
        "        ################\n",
        "        Auc = roc_auc_score(Y_t, Y_score)\n",
        "        average_P_score=average_precision_score(Y_t, Y_score)\n",
        "        print(test[0][0],\"\\t\",round (Auc,3),\"\\t\",round (average_P_score,3))\n",
        "        AUC_ROC_final.append(Auc);Avg_P_final.append(average_P_score);\n",
        "        Z.extend(list(Y_score));Yo.extend(list(Y_t))#;Yp.extend(list(yp))\n",
        "        #save complexwise class ratio\n",
        "        \"\"\"\n",
        "        y_test=np.array(y_test)#.cpu().data.numpy())\n",
        "        classratio=round(len(y_test[y_test==0.])/len(y_test[y_test==1.]),2)\n",
        "        classratio_dict[test[0][0]]=classratio\n",
        "        print(classratio,test[0][0])\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        #/content/PPI-Inhibitors/Data/External data/2dyh_all.txt#githubpath+'/Data/External data/2dyh_all.txt\n",
        "        #RFPP_all=PredictRFPPfromFile(githubpath,githubpath+'/Data/External data/2dyh_all.txt',githubpath+'/Data/External data/pdb/',clf,Ptr,Ctr,Pscaler, Cscaler)#(filename,Pdbloc,trainedModel_SVM,Ctr,Ptr)\n",
        "        External_score,External_labels=PredictScorefromFileSVM(githubpath,githubpath+'/Data/External data/2dyh_all.txt',githubpath+'/Data/External data/pdb/',clf,Ptr,Ctr,Pscaler, Cscaler)#(filename,Pdbloc,trainedModel_SVM,Ptr,Ctr)\n",
        "        ExternalscoresLOCO.extend(External_score);Externallabels.extend(External_labels)\n",
        "        External_Auc= roc_auc_score(External_labels, External_score)\n",
        "        External_AP=average_precision_score(External_labels, External_score)\n",
        "        print(\"External_Auc,PR,RFPP\",round (External_Auc,3), round (External_AP,3))#,RFPP_all,\"\\n\")\n",
        "        #########\n",
        "        #Covid19_RFPP_all=PredictRFPPfromFile(githubpath,githubpath+'/Data/External data/HansonACE2hits.txt',githubpath+'/Data/External data/pdb/',clf,Ptr,Ctr,Pscaler, Cscaler)#(filename,Pdbloc,trainedModel_SVM,Ctr,Ptr)\n",
        "        Covid19_External_score,Covid19_External_labels=PredictScorefromFileSVM(githubpath,githubpath+'/Data/External data/HansonACE2hits.txt',githubpath+'/Data/External data/pdb/',clf,Ptr,Ctr,Pscaler, Cscaler)#(filename,Pdbloc,trainedModel_SVM,Ptr,Ctr)\n",
        "        covid19_Externallabels.extend(Covid19_External_labels);covid19_ExternalscoresLOCO.extend(Covid19_External_score)\n",
        "        Covid19_External_Auc= roc_auc_score(Covid19_External_labels, Covid19_External_score)\n",
        "        Covid19_External_AP=average_precision_score(Covid19_External_labels, Covid19_External_score)\n",
        "        print(\"Covid19_External_Auc,PR,RFPP\",round (Covid19_External_Auc,3), round (Covid19_External_AP,3))#,Covid19_RFPP_all,\"\\n\")\n",
        "    #####\n",
        "    External_fpr, External_tpr, External_thresholds = roc_curve(Externallabels,ExternalscoresLOCO)\n",
        "    External_Auc = roc_auc_score(Externallabels,ExternalscoresLOCO)\n",
        "    External_Auc=(External_Auc).round(2)\n",
        "    fig = plt.figure()\n",
        "    plt.plot(External_fpr, External_tpr,color='k',marker='d',label='External_Auc:{: .2f}'.format(External_Auc))\n",
        "    plt.title('AUCROC External');plt.xlabel('FPR');plt.ylabel('TPR');plt.grid();plt.legend();plt.show();\n",
        "    fig .savefig(path+\"AUCROC External SVM PPI Inhibitors Random and Binders combine Negative.pdf\", bbox_inches='tight')\n",
        "    ########\n",
        "    covid19_External_fpr, covid19_External_tpr, covid19_External_thresholds = roc_curve(covid19_Externallabels,covid19_ExternalscoresLOCO)\n",
        "    covid19_External_Auc = roc_auc_score(covid19_Externallabels,covid19_ExternalscoresLOCO)\n",
        "    covid19_External_Auc=(covid19_External_Auc).round(2)\n",
        "    fig = plt.figure()\n",
        "    plt.plot(covid19_External_fpr, covid19_External_tpr,color='k',marker='d',label='covid19_External_Auc:{: .2f}'.format(covid19_External_Auc))\n",
        "    plt.title('covid19 AUCROC External');plt.xlabel('FPR');plt.ylabel('TPR');plt.grid();plt.legend();plt.show();\n",
        "    fig .savefig(path+\"AUCROC covid19 External SVM PPI Inhibitors Random and Binders combine Negative.pdf\", bbox_inches='tight')\n",
        "    ########\n",
        "    \"\"\"\n",
        "    ###\n",
        "    #pickle.dump(classratio_dict,open('/content/drive/MyDrive/GNN-PPI-Inhibitor'+'/Classratio_dict.npy','wb'))\n",
        "    fpr, tpr, thresholds = roc_curve(Yo, Z)  \n",
        "    Auc = roc_auc_score(Yo, Z)\n",
        "    Auc=(Auc).round(2)\n",
        "    # calculate precision-recall curve\n",
        "    precision, recall, thresholds = precision_recall_curve(Yo, Z)\n",
        "    aucpr=auc(recall,precision)\n",
        "    aucpr=(aucpr).round(2)\n",
        "    #####\n",
        "    Yo=np.array(Yo)\n",
        "    print(\"AucROC and aucpr\\n\",Auc,\"\\n\",aucpr,\"\\ntotal P:N ration 1:\",int (np.sum([Yo==-1.0])/np.sum([Yo==1.0])),\"\\n\")\n",
        "    ######\n",
        "    path=githubpath\n",
        "    fig = plt.figure()\n",
        "    plt.plot(fpr,tpr,color='k',marker='d',label='AUC:{: .2f}'.format(Auc))\n",
        "    plt.title('AUCROC');plt.xlabel('FPR');plt.ylabel('TPR');plt.grid();plt.legend();plt.show();\n",
        "    fig .savefig(path+\"AUCROC MLP-seqFeatures PPI Inhibitors Random and Binders combine Negative.pdf\", bbox_inches='tight')\n",
        "    ###\n",
        "    precision, recall, thresholds = precision_recall_curve(Yo, Z)\n",
        "    aucpr=average_precision_score (Yo, Z)  \n",
        "    ######\n",
        "    fig = plt.figure()\n",
        "    plt.plot(recall,precision,color='m',marker=',',label='AUC-PR:{: .2f}'.format(aucpr))\n",
        "    plt.title('AUC-PR');plt.xlabel('Recall');plt.ylabel('Precision');plt.grid();plt.legend();plt.show();\n",
        "    fig .savefig(path+\"AUC-PR MLP-seqFeatures PPI Inhibitors  Random and Binders combine.pdf\", bbox_inches='tight')\n",
        "    print(\"Final average over all folds,Leave one complex out\",np.average(AUC_ROC_final).round(4),'±',np.std( AUC_ROC_final).round(4),np.average(Avg_P_final).round(4),'±',np.std( Avg_P_final).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAxX-_okyrnW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk8eib-m3eAW"
      },
      "outputs": [],
      "source": [
        "classratio_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lITo__L16Gv"
      },
      "outputs": [],
      "source": [
        "pickle.dump(classratio_dict,open(githubpath+'Features/Classratio_dict.npy','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lik0_Y4rlJ9"
      },
      "outputs": [],
      "source": [
        "y_test=np.array(y_test)#.cpu().data.numpy())\n",
        "classratio=len(y_test[y_test==0.])/len(y_test[y_test==1.])\n",
        "print(classratio,test[0][0])\n",
        "classratio_dict={}\n",
        "classratio_dict[test[0][0]]=classratio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1lZitOIrGHQ"
      },
      "outputs": [],
      "source": [
        "y_train=np.array(y_train.cpu().data.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b6z2flUrUum"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozXbRtaXocmc"
      },
      "outputs": [],
      "source": [
        "train[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIeAnTboeyon"
      },
      "outputs": [],
      "source": [
        "train[n][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_R0c4HQekD8"
      },
      "outputs": [],
      "source": [
        "complexname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VliD-BHJpKbS"
      },
      "outputs": [],
      "source": [
        "len(y_train[y_train==1.])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a28Acuy-pSi8"
      },
      "outputs": [],
      "source": [
        "classratio=len(y_test[y_test==0.])/len(y_test[y_test==1.])\n",
        "classratio_dict={}\n",
        "classratio_dict[test[0][0]]=classratio\n",
        "print(classratio,test[0[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdK-9iYCcBX-"
      },
      "outputs": [],
      "source": [
        "#y_train=np.array(y_train.cpu().data.numpy())\n",
        "np.sum(np.where(y_train[y_train==1.]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anWy61qocVn0"
      },
      "outputs": [],
      "source": [
        "plt.hist(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBXjTEiXa1X_"
      },
      "outputs": [],
      "source": [
        "KK[-100:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vIvfb_Y9SVv"
      },
      "outputs": [],
      "source": [
        "for nt in range(len(test)):\n",
        "  complexname,Ligandname =test[nt][1]\n",
        "  print (Ligandname,CompoundFingerprintFeaturesDict[Ligandname])\n",
        "  #complexname,Complex_AllFeatures_dict[complexname],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnTTAJChwe9r"
      },
      "outputs": [],
      "source": [
        "print(test[0][0],\"\\t\",round (Auc,3),\"\\t\",round (average_P_score,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HsT9lG2vvFl"
      },
      "outputs": [],
      "source": [
        "t[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIBt61FCtWfY"
      },
      "outputs": [],
      "source": [
        "for nt in range(len(test)):\n",
        "  complexname,Ligandname =test[nt][1]\n",
        "  print (Cttdict[Ligandname])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnE_RpAaJ9C6"
      },
      "outputs": [],
      "source": [
        "print (Ptt[0:11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqRWiqDHHX1v"
      },
      "outputs": [],
      "source": [
        "y_test=[];Y_t=[];Y_score=[];\n",
        "for n in range(len(test)):\n",
        "    y_test.append(Allexamples[test[n][0],test[n][1]])\n",
        "#y_test=torch.FloatTensor( y_test).cuda()\n",
        "for nt in range(len(test)):\n",
        "  complexname,Ligandname =test[nt][1]\n",
        "  test_score=IPPI_Net(CompoundNet,Complex_AllFeatures_dict[complexname],CompoundFingerprintFeaturesDict[Ligandname])\n",
        "  Y_score.extend(test_score.cpu().data.numpy())\n",
        "  Y_t.append(y_test[nt])#.cpu().data.numpy())\n",
        "################\n",
        "Auc = roc_auc_score(Y_t, Y_score)\n",
        "average_P_score=average_precision_score(Y_t, Y_score)\n",
        "#        print(\"\\nfold Auc:\",Auc,\"average_P_score=\",average_P_score ,\"P\",len(testPos),\"N\",len(testNeg))\n",
        "print(t[0],\"\\t\",round (Auc,3),\"\\t\",round (average_P_score,3))# ,\"\\t\",len(),\"\\t\",len(testNegcomp),\"\\t\",round (len(testNegcomp) /len(testPoscomp),1))\n",
        "#        pdb.set_trace()\n",
        "AUC_ROC_final.append(Auc);Avg_P_final.append(average_P_score);\n",
        "Z.extend(list(z));Yo.extend(list(y_test))#;Yp.extend(list(yp))\n",
        "#######################3\n",
        "#/content/PPI-Inhibitors/Data/External data/2dyh_all.txt#githubpath+'/Data/External data/2dyh_all.txt\n",
        "#RFPP_all=PredictRFPPfromFile(githubpath,githubpath+'/Data/External data/2dyh_all.txt',githubpath+'/Data/External data/pdb/',clf,Ptr,Ctr,Pscaler, Cscaler)#(filename,Pdbloc,trainedModel_SVM,Ctr,Ptr)\n",
        "External_score,External_labels=PredictScorefromFileSVM(githubpath,githubpath+'/Data/External data/2dyh_all.txt',githubpath+'/Data/External data/pdb/',clf,Ptr,Ctr,Pscaler, Cscaler)#(filename,Pdbloc,trainedModel_SVM,Ptr,Ctr)\n",
        "ExternalscoresLOCO.extend(External_score);Externallabels.extend(External_labels)\n",
        "External_Auc= roc_auc_score(External_labels, External_score)\n",
        "External_AP=average_precision_score(External_labels, External_score)\n",
        "print(\"External_Auc,PR,RFPP\",round (External_Auc,3), round (External_AP,3))#,RFPP_all,\"\\n\")\n",
        "#########\n",
        "#Covid19_RFPP_all=PredictRFPPfromFile(githubpath,githubpath+'/Data/External data/HansonACE2hits.txt',githubpath+'/Data/External data/pdb/',clf,Ptr,Ctr,Pscaler, Cscaler)#(filename,Pdbloc,trainedModel_SVM,Ctr,Ptr)\n",
        "Covid19_External_score,Covid19_External_labels=PredictScorefromFileSVM(githubpath,githubpath+'/Data/External data/HansonACE2hits.txt',githubpath+'/Data/External data/pdb/',clf,Ptr,Ctr,Pscaler, Cscaler)#(filename,Pdbloc,trainedModel_SVM,Ptr,Ctr)\n",
        "covid19_Externallabels.extend(Covid19_External_labels);covid19_ExternalscoresLOCO.extend(Covid19_External_score)\n",
        "Covid19_External_Auc= roc_auc_score(Covid19_External_labels, Covid19_External_score)\n",
        "Covid19_External_AP=average_precision_score(Covid19_External_labels, Covid19_External_score)\n",
        "print(\"Covid19_External_Auc,PR,RFPP\",round (Covid19_External_Auc,3), round (Covid19_External_AP,3))#,Covid19_RFPP_all,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcxG5kdURv8U"
      },
      "outputs": [],
      "source": [
        "plt.hist(Y_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUIZJYSZIvWn"
      },
      "outputs": [],
      "source": [
        "Y_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqm9hK1MIh7Q"
      },
      "outputs": [],
      "source": [
        "y_test[nt]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5UeuFjkIXkt"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIqmO7JVHqDo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhxWJTdj7Yu6"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(Batchlosslist)\n",
        "plt.title('batchloss');plt.xlabel('epochs');plt.ylabel('loss');plt.grid();plt.legend();plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJY96wWhllpO"
      },
      "outputs": [],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HjqAhyYhkwy"
      },
      "outputs": [],
      "source": [
        "Complex_AllFeatures_dict[complexname].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gZM_PnKe0ap"
      },
      "outputs": [],
      "source": [
        "Allexamples[train[n][0],train[n][1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzTn4ElhfPXH"
      },
      "outputs": [],
      "source": [
        "train[n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f5bvm31fdZJ"
      },
      "outputs": [],
      "source": [
        "train[n][0],train[n][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-LtAAOpx1Mv"
      },
      "outputs": [],
      "source": [
        "plt.plot(External_score)\n",
        "plt.figure()\n",
        "plt.plot(External_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR9tbUtf2_tr"
      },
      "outputs": [],
      "source": [
        "External_fpr, External_tpr, External_thresholds = roc_curve(Externallabels,ExternalscoresLOCO)\n",
        "External_Auc = roc_auc_score(Externallabels,ExternalscoresLOCO)\n",
        "External_Auc=(External_Auc).round(2)\n",
        "fig = plt.figure()\n",
        "plt.plot(External_fpr, External_tpr,color='k',marker='d',label='External_Auc:{: .2f}'.format(External_Auc))\n",
        "plt.title('AUCROC External');plt.xlabel('FPR');plt.ylabel('TPR');plt.grid();plt.legend();plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vx63agu3MrZ"
      },
      "outputs": [],
      "source": [
        "ExternalscoresLOCO"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}