# -*- coding: utf-8 -*-
"""
Created on Sat Apr 10 20:01:32 2021
@author: fayya
"""
from rdkit import Chem
from rdkit.Chem import AllChem
from rdkit.Chem.Draw import IPythonConsole
from rdkit.Chem import DataStructs
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm as tqdm
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score,roc_curve,precision_score,recall_score,average_precision_score
#rdkit.Avalon.pyAvalonTools.GetAvalonCountFP((object)mol[, (int)nBits=512[, (bool)isQuery=False[, (int)bitFlags=15761407]]])
#from rdkit.Avalon import pyAvalonTools as pat
def LoadSuperDrugdata():
  path='/content/drive/MyDrive/CPI_Data/'
  import pandas as pd
  df_Superdrug=pd.read_excel(path+'approved_drugs_chemical_structure_identifiers.xlsx',usecols="C").values#index_col=2)
  df_Superdrug=df_Superdrug[1:]
  ###Names
  SuperdrugNames=pd.read_excel(path+'approved_drugs_chemical_structure_identifiers.xlsx',usecols="B").values#index_col=2)
  SuperdrugNames=SuperdrugNames[1:]
  SuperdrugNames=np.array([c[0] for c in SuperdrugNames])
  df_Superdrug_Compounds=np.array([c[0] for c in df_Superdrug])#3638
  CompoundFeatures = np.array([getFP(s) for s in df_Superdrug_Compounds])
  return CompoundFeatures,SuperdrugNames 
def PredictscorefromPair(Ptr, Ctr,Pscaler,Cscaler,Proteinfeatures,Compoundsfeatures,n,Labels):
  #Ptr, Ctr is Protein and Compound kernel
  #s is list of protein sequence C is the list of compounds
  #n is the top hits
  CTCS = Compoundsfeatures#np.array([getFP(c) for c in Compoundslist])
  PTCS= Proteinfeatures#np.array([prot_feats_seq(s) for s in Proteinslist])
  ####
  PTCS,CTCS = Pscaler.transform(PTCS), Cscaler.transform(CTCS)
  #####
  Ktp = kernel(PTCS,Ptr)
  Ktc = kernel(CTCS,Ctr)
  Ktcp = (Ktp+Ktc)**2# (Kp**2+Kc**2+2*Kp*Kc)
  TCS = clf.decision_function(Ktcp)
  ###Sorting
  index_TCS=np.argsort(TCS)
  #n=len(SuperdrugNames)
  sorted_index=index_TCS[::-1][:n]
  sorted_score=TCS[sorted_index]#[index_TCS[::-1][:n]]
  sorted_Labels=Labels[sorted_index]
  return sorted_index,sorted_score,sorted_Labels
def PredictTopNscores(Ptr, Ctr,s,n):
  #Ptr, Ctr is Protein and Compound kernel
  #s is protein sequence for Target Compound screening (TCS), n is the top prediction from Superdrugbank2
  path='/content/drive/MyDrive/CPI_Data/'
  import pandas as pd
  df_Superdrug=pd.read_excel(path+'approved_drugs_chemical_structure_identifiers_remdesivir.xlsx',usecols="C").values#approved_drugs_chemical_structure_identifiers.xlsx',usecols="C").values#index_col=2)
  #approved_drugs_chemical_structure_identifiers_remdesivir
  df_Superdrug=df_Superdrug[1:]
  ###Names
  SuperdrugNames=pd.read_excel(path+'approved_drugs_chemical_structure_identifiers_remdesivir.xlsx',usecols="B").values#'approved_drugs_chemical_structure_identifiers.xlsx'
  SuperdrugNames=SuperdrugNames[1:]
  ###
  df_Superdrug_Compounds=np.array([c[0] for c in df_Superdrug])#3638
  #df_Superdrug_Compounds=list (set (df_Superdrug_Compounds))#only unique 3633
  Superdrug_CFeatures = np.array([getFP(s) for s in df_Superdrug_Compounds])
  Pfeatures= prot_feats_seq(s)
  ###
  PTCS=np.array([Pfeatures for i in range(len(Superdrug_CFeatures))])#Copy same feature of protein equal to number of unique compounds
  CTCS=Superdrug_CFeatures
  PTCS,CTCS = Pscaler.transform(PTCS), Cscaler.transform(CTCS)
  Ktp = kernel(PTCS,Ptr)
  Ktc = kernel(CTCS,Ctr)
  Ktcp = (Ktp+Ktc)**2# (Kp**2+Kc**2+2*Kp*Kc)
  TCS = clf.decision_function(Ktcp)
  ###Sorting
  index_TCS=np.argsort(TCS)
  #n=len(SuperdrugNames)
  sorted_index=index_TCS[::-1][:n]
  sorted_score=TCS[sorted_index]#index_TCS[::-1][:n]]
  sorted_SuperdrugNames=SuperdrugNames[sorted_index]
  return sorted_SuperdrugNames,sorted_score
def DataWriteExcelNewsheet(Name,Ratio,n,fold,ACE2Names,ACE2scores):
  ###Writing in EXcel
  import xlsxwriter
  Filename=path+Name+'ResultsNegativeRatio'+Ratio+'Fold'+str (fold)+'.xlsx'
  workbook = xlsxwriter.Workbook(Filename)#path+Name+'ResultsNegativeRatio'+Ratio+'Fold'+str (fold)+'.xlsx')
  worksheet = workbook.add_worksheet()
  col = 0;row = 0;
  worksheet.write(row, col, ' Fold')
  worksheet.write(row, col+1, Name+'Compund no')
  #worksheet.write(row, col+1, 'SMILES')
  worksheet.write(row, col+2, Name+'Names')
  worksheet.write(row, col+3, Name+'Score')
  """
  worksheet.write(row, col+4, ' Spike Compund no')
  worksheet.write(row, col+5, 'Spike Names')
  worksheet.write(row, col+6, 'Spike Score')
  """
  for i in range(n):
    row = i+1
    print("i",i)
    #####
    worksheet.write(row, col, fold)
    worksheet.write(row, col+1, i+1)
    worksheet.write(row, col+2, ACE2Names[i])
    worksheet.write(row, col+3, np.round(ACE2scores[i],2))
    """"
    worksheet.write(row, col+4, i+1)
    worksheet.write(row, col+5, SpikeNames[i][0])
    worksheet.write(row, col+6, np.round(Spikescores[i],2))
    """
  workbook.close() 
def DataWriteExcel(Name,Ratio,n,fold,ACE2Names,ACE2scores,SpikeNames,Spikescores):
  ####
  ###Writing in EXcel
  import xlsxwriter
  workbook = xlsxwriter.Workbook(path+Name+'ResultsNegativeRatio'+Ratio+'Fold'+str (fold)+'.xlsx')
  worksheet = workbook.add_worksheet()
  col = 0;row = 0;
  worksheet.write(row, col, ' Fold')
  worksheet.write(row, col+1, ' ACE2 Compund no')
  #worksheet.write(row, col+1, 'SMILES')
  worksheet.write(row, col+2, 'ACE2 Names')
  worksheet.write(row, col+3, 'ACE2 Score')
  worksheet.write(row, col+4, ' Spike Compund no')
  worksheet.write(row, col+5, 'Spike Names')
  worksheet.write(row, col+6, 'Spike Score')
  for i in range(n):
    row = i+1
    print("i",i)
    #####
    worksheet.write(row, col, fold)
    worksheet.write(row, col+1, i+1)
    worksheet.write(row, col+2, ACE2Names[i][0])
    worksheet.write(row, col+3, np.round(ACE2scores[i],2))
    worksheet.write(row, col+4, i+1)
    worksheet.write(row, col+5, SpikeNames[i][0])
    worksheet.write(row, col+6, np.round(Spikescores[i],2))
  workbook.close() 
  
def getFP(s,r = 3,nBits = 1024):        
    compound = Chem.MolFromSmiles(s.strip())
    fp = AllChem.GetMorganFingerprintAsBitVect(compound, r, nBits = nBits)
    #fp = pat.GetAvalonCountFP(compound,nBits=nBits)
    m = np.zeros((0, ), dtype=np.int8)
    DataStructs.ConvertToNumpyArray(fp, m)     
    return m
from rdkit import Chem
from rdkit.Chem.Draw import IPythonConsole
from rdkit.Chem import rdDepictor
from rdkit.Chem.Draw import rdMolDraw2D
from IPython.display import SVG

import random
import numpy as np
def NRKFold(E,pc,K = 5, shuffle=True):
    """
    Generate non-redundant K-folds so that no two folds contain proteins
    belonging to the same cluster and the number of examples are (approx)
    equal in all folds. Implements the greedy number partitioning method
    https://en.wikipedia.org/wiki/Greedy_number_partitioning
    >>> NRKFold(['p1','p2','p3','p4','p5','p6','p1'],{'p1':1,'p2':2,'p3':1,'p4':2,'p5':3,'p6':3},K=2, shuffle = False)
    Here we have 7 examples involving 6 proteins p1-p6 such that proteins
    p1,p3,p5 form one cluster whereas p2,p4,p6 form another cluster
    This results in division into two folds as [[0, 2, 6], [1, 3, 4, 5]]
    Note that examples 0,2,6 comprising fold-1 with proteins p1 and p2 are 
    from the first cluster whereas the remaining examples are from other clusters
    Parameters
    ----------
    E : TYPE List (length equal to number of examples)
        DESCRIPTION. Protein id of protein involved in each example
    pc : TYPE dictionary 
        DESCRIPTION. Cluster assignment of each protein
    K : TYPE, optional Integer
        DESCRIPTION. Number of folds The default is 5.
    shuffle: TYPE, Boolean
        cluster to fold assignments are different across different runs
    Returns
    -------
    F : TYPE list of lists
        DESCRIPTION. Indices of examples in E in each fold
    """
    e = [pc[str(x)] for x in E] #cluster indices of all proteins in the examples
    c2idx={} #indices of examples of each cluster in e
    for i,x in enumerate(e):
        try: 
            c2idx[x].append(i)
        except:
            c2idx[x]=[i]    
    ce = dict([(c,len(c2idx[c])) for c in c2idx]) #counts of examples of different clusters    
    cF = [0]*K; #counts of examples in each fold
    CF = [[] for _ in range(K)]; #clusters in each fold
    F = [[] for _ in range(K)];#indices of examples in each fold
    keys = list(ce.keys())
    if shuffle:
        random.shuffle(keys)
    for k in keys:
        v = ce[k]
        idx = np.argmin(cF)
        cF[idx]+=v
        CF[idx].append(k) #add cluster to fold
        F[idx].extend(c2idx[k])
    return F
import os
from Bio import SeqIO
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
def processCDHIT(L,cthresh,ofile="out.cdhit"):#=0.8
    """   
    Generate CD-HIT clustering
    Runs CD-HIT and creates a temporary file which is not deleted automatically
    Parameters
    ----------
    L : TYPE Fasta file string OR List of protein sequences OR  SeqRecord
        DESCRIPTION.
    cthresh : TYPE, optional
        DESCRIPTION. Cutoff threshold The default is 0.8.
    ofile : TYPE, optional
        DESCRIPTION. The default is "out.cdhit".
    Returns
    -------
    cc : TYPE Dictionary with cluster id  as key and list of protein ids in each cluster
        DESCRIPTION. 
    pc: TYPE Dictionary with protein id string as key and cluster id as value
        DESCRIPTION. 
    """
    if type(L)==type(""):
        ifile = L
    else:
        if type(L[0]==type("")):
            L = [SeqRecord(Seq(p),id=str(i)) for i,p in enumerate(L)]
        ifile = ofile+"_temp.fasta"
        with open(ifile, "w") as output_handle:
            SeqIO.write(L, output_handle, "fasta") 
    
    cmd = "cd-hit -i "+ifile+" -d 0 -o "+ofile+" -c "+str(cthresh)+" -n 3  -G 1 -g 1 -b 20 -l 10 -s 0.0 -aL 0.0 -aS 0.0 -T 4 -M 32000"   
    os.system(cmd)
    with open(ofile+".clstr","r") as fh:
        clusters = fh.readlines()
    cc = {}
    for x in clusters:
        xs = x.split()
        if xs[0]=='>Cluster':
            ccid = int(xs[1])
            cc[ccid]=[]
        else:
            pid = xs[2][1:].split('...')[0]
            cc[ccid].append(pid)  
    pc = {}
    for k,v in cc.items():
        for vi in v:
            pc[vi]=k
    return cc,pc

def moltosvg(mol, molSize = (300,300), kekulize = True):
    mc = Chem.Mol(mol.ToBinary())
    if kekulize:
        try:
            Chem.Kekulize(mc)
        except:
            mc = Chem.Mol(mol.ToBinary())
    if not mc.GetNumConformers():
        rdDepictor.Compute2DCoords(mc)
    drawer = rdMolDraw2D.MolDraw2DSVG(molSize[0],molSize[1])
    drawer.DrawMolecule(mc)
    drawer.FinishDrawing()
    svg = drawer.GetDrawingText()
    return svg.replace('svg:','')


from Bio import SeqIO
from Bio.SeqIO import FastaIO
from itertools import product
from Bio.SeqUtils.ProtParam import ProteinAnalysis
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import normalize
import math
def twomerFromSeq(s):
    k=2
    groups={'A':'1','V':'1','G':'1','I':'2','L':'2','F':'2','P':'2','Y':'3',
            'M':'3','T':'3','S':'3','H':'4','N':'4','Q':'4','W':'4',
            'R':'5','K':'5','D':'6','E':'6','C':'7'}
    crossproduct=[''.join (i) for i in product("1234567",repeat=k)]
    for i in range (0,len(crossproduct)): crossproduct[i]=int(crossproduct[i])
    ind=[]
    for i in range (0,len(crossproduct)): ind.append(i)
    combinations=dict(zip(crossproduct,ind))

    V=np.zeros(int((math.pow(7,k))))      #defines a vector of 343 length with zero entries
    try:
        for j in range (0,len(s)-k+1):
            kmer=s[j:j+k]
            c=''
            for l in range(0,k):
                c+=groups[kmer[l]]
                V[combinations[int(c)]]+=1
    except:
        count={'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0}
        for q in range(0,len(s)):
            if s[q]=='A' or s[q]=='V' or s[q]=='G':
                count['1']+=1
            if s[q]=='I' or s[q]=='L'or s[q]=='F' or s[q]=='P':
                count['2']+=1
            if s[q]=='Y' or s[q]=='M'or s[q]=='T' or s[q]=='S':
                count['3']+=1
            if s[q]=='H' or s[q]=='N'or s[q]=='Q' or s[q]=='W':
                count['4']+=1
            if s[q]=='R' or s[q]=='K':
                count['5']+=1
            if s[q]=='D' or s[q]=='E':
                count['6']+=1
            if s[q]=='C':
                count['7']+=1
        val=list(count.values()  )           #[ 0,0,0,0,0,0,0]
        key=list(count.keys()     )           #['1', '2', '3', '4', '5', '6', '7']
        m=0
        ind=0
        for t in range(0,len(val)):     #find maximum value from val
            if m<val[t]:
                m=val[t]
                ind=t
        m=key [ind]                     # m=group number of maximum occuring group alphabets in protein
        for j in range (0,len(s)-k+1):
            kmer=s[j:j+k]
            c=''
            for l in range(0,k):
                if kmer[l] not in groups:
                    c+=m
                else:
                    c+=groups[kmer[l]]
            V[combinations[int(c)]]+=1

    V=V/(len(s)-1)
    return np.array(V)
def threemerFromSeq(s):
    k=3
    groups={'A':'1','V':'1','G':'1','I':'2','L':'2','F':'2','P':'2','Y':'3',
            'M':'3','T':'3','S':'3','H':'4','N':'4','Q':'4','W':'4',
            'R':'5','K':'5','D':'6','E':'6','C':'7'}
    crossproduct=[''.join (i) for i in product("1234567",repeat=k)]
    for i in range (0,len(crossproduct)): crossproduct[i]=int(crossproduct[i])
    ind=[]
    for i in range (0,len(crossproduct)): ind.append(i)
    combinations=dict(zip(crossproduct,ind))

    V=np.zeros(int((math.pow(7,k))))      #defines a vector of 343 length with zero entries
    try:
        for j in range (0,len(s)-k+1):
            kmer=s[j:j+k]
            c=''
            for l in range(0,k):
                c+=groups[kmer[l]]
                V[combinations[int(c)]]+=1
    except:
        count={'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0}
        for q in range(0,len(s)):
            if s[q]=='A' or s[q]=='V' or s[q]=='G':
                count['1']+=1
            if s[q]=='I' or s[q]=='L'or s[q]=='F' or s[q]=='P':
                count['2']+=1
            if s[q]=='Y' or s[q]=='M'or s[q]=='T' or s[q]=='S':
                count['3']+=1
            if s[q]=='H' or s[q]=='N'or s[q]=='Q' or s[q]=='W':
                count['4']+=1
            if s[q]=='R' or s[q]=='K':
                count['5']+=1
            if s[q]=='D' or s[q]=='E':
                count['6']+=1
            if s[q]=='C':
                count['7']+=1
        val=list(count.values())              #[ 0,0,0,0,0,0,0]
        key=list(count.keys() )              #['1', '2', '3', '4', '5', '6', '7']
        m=0
        ind=0
        for t in range(0,len(val)):     #find maximum value from val
            if m<val[t]:
                m=val[t]
                ind=t
        m=key [ind]                     # m=group number of maximum occuring group alphabets in protein
        for j in range (0,len(s)-k+1):
            kmer=s[j:j+k]
            c=''
            for l in range(0,k):
                if kmer[l] not in groups:
                    c+=m
                else:
                    c+=groups[kmer[l]]
            V[combinations[int(c)]]+=1

    V=V/(len(s)-1)
    return np.array(V)
def prot_feats_seq(seq):
    aa=['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']
    f=[]
    X = ProteinAnalysis(str(seq))
    X.molecular_weight() #throws an error if 'X' in sequence. we skip such sequences
    p=X.get_amino_acids_percent()
    dp=[]
    for a in aa:
        dp.append(p[a])
    dp=np.array(dp)
    dp=normalize(np.atleast_2d(dp), norm='l2', copy=True, axis=1, return_norm=False)
    f.extend(dp[0])
    tm=np.array(twomerFromSeq(str(seq)))
    tm=normalize(np.atleast_2d(tm), norm='l2', copy=True, axis=1,return_norm=False)
    f.extend(tm[0])
    thm=np.array(threemerFromSeq(str(seq)))
    thm=normalize(np.atleast_2d(thm), norm='l2', copy=True, axis=1,return_norm=False)
    f.extend(thm[0])
    return np.array(f)
def DataWrite(Cseq,Pseq,Y, filename):
  path='/content/drive/MyDrive/CPI_Data/'
  filename=open(path+filename+'.txt','w', encoding="utf-8")
  for data in range(len(Cseq)):
    filename.write((Cseq[data]+' '+Pseq[data]+' '+str(Y[data])+"\n"))
def Features_Predictor(filename):
  path='/content/drive/MyDrive/CPI_Data/'
  with open(path+filename) as f:#'2p2i_TargetvsNonTargetchain_human.txt') as f:#New_Unique_data.txt') as f:#
    #with open('./data.txt') as f:#../../celegans/original
    D = f.readlines()
  C=[];P=[];Y=[];Cseq=[];Pseq=[]
  Ids=[];Ligands=[];Complexs=[];Chains=[];
  for d in tqdm(D):
      Id,Ligand,Complex,Chain,c,p,y = d.split()
      #id,c,p,y = d.split()
      try:
          xc = getFP(c)
          xp = prot_feats_seq(p)
      except Exception as e:
          print(e)
          continue
      Cseq.append(c)
      Pseq.append(p)
      C.append(xc)
      P.append(xp)
      Y.append(2*float(y)-1)
      ####
      Ids.append(Id);Ligands.append(Ligand);Complexs.append(Complex);Chains.append(Chain);
  Y = np.array(Y);
  C = np.array(C);
  P = np.array(P);
  return P,C,Y
import collections
from collections import defaultdict
def combineDict(dict1, dict2):
    res = collections.defaultdict(list)
    for key, value in (dict1.items() | dict2.items()):
        res[key].append(value)
    return res
from sklearn.svm import LinearSVC,SVC
from sklearn.metrics.pairwise import rbf_kernel as kernel #sigmoid_kernel,rbf_kernel,linear_kernel
from sklearn.model_selection import StratifiedKFold, KFold
import random
if __name__=='__main__':
    NegtiveRatio='1'#7
    path='/content/drive/MyDrive/CPI_Data/'
    #with open(path+'Orignal_CPI_data.txt') as f:
    #with open(path+'Orignal_CPI_data.txt') as f:#6725
    with open(path+'pos2negtiveRatio'+NegtiveRatio+'_Alpha_threshold_Random.txt') as f:
    #with open('./data.txt') as f:#../../celegans/original
        D = f.readlines()
    C=[];P=[];Y=[];Cseq=[];Pseq=[]
    for d in tqdm(D):
        c,p,y = d.split()
        #id,c,p,y = d.split()
        try:
            xc = getFP(c)
            xp = prot_feats_seq(p)
        except Exception as e:
            print(e)
            continue
        Cseq.append(c)
        Pseq.append(p)
        C.append(xc)
        P.append(xp)
        #Y.append(2*float(y)-1)#Orignal
        Y.append(float(y))#when read from file which have already negative examples as -1
    Y = np.array(Y)
    C = np.array(C);
    P = np.array(P);
    print("Total length=",len(P),"Total positive",len(Y[Y==1]),"Total Negative",len(Y[Y!=1])) 
#%% Generating negative examples  
    regenerate =  False#
    if regenerate:
        Pset = list(set(Pseq)) #set of protein sequences
        pidx = list(range(len(Pset))) 
        Pdict = dict(zip(Pset, pidx)) #seq->index
        Cset = list(set(Cseq)) #set of compound sequences
        cidx = list(range(len(Cset)))#
        Cdict = dict(zip(Cset, cidx)) #str->index
        Epairs = np.array([(Pdict[p],Cdict[c]) for (p,c) in zip(Pseq,Cseq)]) #dict of pairs
        pos,negs = Epairs[Y==1,:],Epairs[Y!=1,:] 
        #if the negs are to be sampled such that the both the protein and compound occur in the positive set as well
        #pidx,cidx = list(set(pos[:,0])),list(set(pos[:,1])) 
        #pos, negs = list(map(tuple,pos.tolist())),list(map(tuple,negs.tolist())) #
        #below - remove 100% redundant positive and negative examples -- original redundant examples are not removed otherwise
        pos, negs = list(set(map(tuple,pos.tolist()))),list(set(map(tuple,negs.tolist())))
        Lnegs = len(negs)
        """
        NegtiveRatio=7
        NN =NegtiveRatio*len(pos)#len(negs) #
        negs = [] #comment to use the set of original negatives
        ######## Dissimilarity Criteria for negtive examples
        Pos_PFeatures = np.array([prot_feats_seq(Pset[s[0]]) for s in pos])
        Pos_Pseq=np.array([s[0] for s in pos])
        Pos_CFeatures = np.array([getFP(Cset[s[1]]) for s in pos])
        Pos_Cseq=np.array([s[1] for s in pos])
        #######
        Pos_Pscaler = StandardScaler().fit(Pos_PFeatures )
        Pos_Cscaler = StandardScaler().fit(Pos_CFeatures)
        Pos_Ptr,Pos_Ctr = Pos_Pscaler.transform(Pos_PFeatures), Pos_Cscaler.transform(Pos_CFeatures)
        #####
        Kpp = kernel(Pos_Ptr)
        Kcp = kernel(Pos_Ctr)
        Kpp_dict=dict(zip(Pos_Pseq,Kpp))
        Kcp_dict=dict(zip(Pos_Cseq,Kcp))
        ######
        Alpha_threshold='Random'#0.03
        while len(negs)<NN:
          possible = (random.choice(pidx),random.choice(cidx))#(pidx[np.random.randint(0,len(ppos))],cidx[np.random.randint(0,len(cpos))])
          index_P=np.argmax(Kpp_dict[possible[0]])
          new_Spp=np.delete(Kpp[index_P],index_P)
          index_C=np.argmax(Kcp_dict[possible[1]])
          new_Scp=np.delete(Kcp[index_C],index_C)
          Alpha=np.max(new_Spp)*np.max(new_Scp)
          if possible not in pos and possible not in negs and Alpha<Alpha_threshold:
              negs.append(possible)      
        """  
        print('Added Negatives',len(negs)-Lnegs)
        iPdict = {v: k for k, v in Pdict.items()}
        iCdict = {v: k for k, v in Cdict.items()}
        
        C=[];P=[];Y=[];Cseq=[];Pseq=[]
        for i,(p,c) in tqdm(enumerate(pos+negs)):
            p = iPdict[p]
            c = iCdict[c]
            try:
                xc = getFP(c)
                xp = prot_feats_seq(p)
            except Exception as e:
                print(e)
                continue
            Cseq.append(c)
            Pseq.append(p)
            C.append(xc)
            P.append(xp)
            Y.append(2*(i<len(pos))-1)
        
#%%
    Y = np.array(Y)
    C = np.array(C);
    P = np.array(P);
    ####
    Alpha_threshold='Random'
    #filename="pos2negtiveRatio"+str (NegtiveRatio)+"_Alpha_threshold_"+str (Alpha_threshold)
    #DataWrite(Cseq,Pseq,Y, filename)
    import itertools
    Pset = list(set(Pseq)) #set of protein sequences
    pidx = list(range(len(Pset))) 
    Pdict = dict(zip(Pset, pidx)) #seq->index
    Cset = list(set(Cseq)) #set of compound sequences
    cidx = list(range(len(Cset)))#
    Cdict = dict(zip(Cset, cidx)) #str->index
    Epairs = np.array([(Pdict[p],Cdict[c]) for (p,c) in zip(Pseq,Cseq)]) #dict of pairs
#%% 
    cc,pc = processCDHIT(Pset,cthresh = 0.9) 
    
    E = list(Epairs[:,0]) #protein id of examples
    F = NRKFold(E,pc,K=5,shuffle=True)   
    
#%%        
    gp = gc = None
    skf = KFold(n_splits=5,shuffle=True)
    skf = StratifiedKFold(n_splits=5,shuffle=True)        
    F=[list(test_index) for (train_index, test_index) in skf.split(P, Y)] 
    F = NRKFold(E,pc,K=5,shuffle=True) 
    Z = []; Yo = []; A = [];Yp=[]
    AUC_ROC_final=[];Precision_final=[];Recall_final=[];Avg_P_final=[];
    #for train_index, test_index in tqdm(skf.split(P, Y)):
    ###
    ###
    MergeDict={}
    MergeDict_ACE2={}
    MergeDict_Lmj_PABP1={}
    ###load SuperDrugdata
    CompoundFeatures,SuperdrugNames=LoadSuperDrugdata()
    for f in tqdm(range(len(F))):
        train_index = list(itertools.chain.from_iterable(F[:f]+F[f+1:]))
        test_index = F[f]
        #show number of proteins shared between train and test
        print(len(set([E[x] for x in train_index]).intersection([E[x] for x in test_index])))        
        y_train, y_test = Y[train_index], Y[test_index] 
        Ptr,Ctr = P[train_index,:],C[train_index,:]
        Pscaler = StandardScaler().fit(Ptr)
        Cscaler = StandardScaler().fit(Ctr)
        Ptr,Ctr = Pscaler.transform(Ptr), Cscaler.transform(Ctr)
        
        Kp = kernel(Ptr)
        Kc = kernel(Ctr)
        Ktr = (Kp+Kc)**2# (Kp**2+Kc**2+2*Kp*Kc)
        
        clf = SVC(C = 1.0, kernel = 'precomputed',class_weight='balanced')
        clf.fit(Ktr,y_train)
        
        Ptt,Ctt = P[test_index,:],C[test_index,:]
        Ptt,Ctt = Pscaler.transform(Ptt), Cscaler.transform(Ctt)
        
        Kp = kernel(Ptt,Ptr)
        Kc = kernel(Ctt,Ctr)
        Ktt = (Kp+Kc)**2# (Kp**2+Kc**2+2*Kp*Kc)
        
        z = clf.decision_function(Ktt)
        yp=clf.predict(Ktt)
        auc = roc_auc_score(y_test, z)
        precision = precision_score(y_test, yp)
        recall = recall_score(y_test, yp)
        average_P_score=average_precision_score(y_test, z)
        print("fold Auc:",auc,"average_P_score=",average_P_score )
        ###Verify CV with PredictscorefromPair(Ptr, Ctr,Proteinfeatures,Compoundsfeatures,n,Labels)
        sorted_index,sorted_score,sorted_Labels=PredictscorefromPair(Ptr, Ctr,Pscaler,Cscaler,P[test_index,:],C[test_index,:],len(y_test),y_test)
        auc_verify = roc_auc_score(sorted_Labels, sorted_score)
        average_P_verify=average_precision_score(sorted_Labels, sorted_score)
        print("fold auc_verify:",auc_verify,"average_P_verify",average_P_verify )
        AUC_ROC_final.append(auc);Precision_final.append(precision );Recall_final.append(recall);Avg_P_final.append(average_P_score);Z.extend(list(z));Yo.extend(list(y_test))#;Yp.extend(list(yp))
        """
        #####Testing with PredictscorefromPair(Ptr, Ctr,Proteinfeatures,Compoundsfeatures,n,Labels)
        
        ACE2='MSSSSWLLLSLVAVTAAQSTIEEQAKTFLDKFNHEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTLAQMYPLQEIQNLTVKLQLQALQQNGSSVLSEDKSKRLNTILNTMSTIYSTGKVCNPDNPQECLLLEPGLNEIMANSLDYNERLWAWESWRSEVGKQLRPLYEEYVVLKNEMARANHYEDYGDYWRGDYEVNGVDGYDYSRGQLIEDVEHTFEEIKPLYEHLHAYVRAKLMNAYPSYISPIGCLPAHLLGDMWGRFWTNLYSLTVPFGQKPNIDVTDAMVDQAWDAQRIFKEAEKFFVSVGLPNMTQGFWENSMLTDPGNVQKAVCHPTAWDLGKGDFRILMCTKVTMDDFLTAHHEMGHIQYDMAYAAQPFLLRNGANEGFHEAVGEIMSLSAATPKHLKSIGLLSPDFQEDNETEINFLLKQALTIVGTLPFTYMLEKWRWMVFKGEIPKDQWMKKWWEMKREIVGVVEPVPHDETYCDPASLFHVSNDYSFIRYYTRTLYQFQFQEALCQAAKHEGPLHKCDISNSTEAGQKLFNMLRLGKSEPWTLALENVVGAKNMNVRPLLNYFEPLFTWLKDQNKNSFVGWSTDWSPYADQSIKVRISLKSALGDKAYEWNDNEMYLFRSSVAYAMRQYFLKVKNQMILFGEEDVRVANLKPRISFNFFVTAPKNVSDIIPRTEVEKAIRMSRSRINDAFRLNDNSLEFLGIQPTLGPPNQPPVSIWLIVFGVVMGVIVVGIVILIFTGIRDRKKKNKARSGENPYASIDISKGENNPGFQNTDDVQTSF'
        ###
        Spike='MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEIFRSDTLYLTQDLFLPFYSNVTGFHTINHTFGNPVIPFKDGIYFAATEKSNVVRGWVFGSTMNNKSQSVIIINNSTNVVIRACNFELCDNPFFAVSKPMGTQTHTMIFDNAFNCTFEYISDAFSLDVSEKSGNFKHLREFVFKNKDGFLYVYKGYQPIDVVRDLPSGFNTLKPIFKLPLGINITNFRAILTAFSPAQDIWGTSAAAYFVGYLKPTTFMLKYDENGTITDAVDCSQNPLAELKCSVKSFEIDKGIYQTSNFRVVPSGDVVRFPNITNLCPFGEVFNATKFPSVYAWERKKISNCVADYSVLYNSTFFSTFKCYGVSATKLNDLCFSNVYADSFVVKGDDVRQIAPGQTGVIADYNYKLPDDFMGCVLAWNTRNIDATSTGNYNYKYRYLRHGKLRPFERDISNVPFSPDGKPCTPPALNCYWPLNDYGFYTTTGIGYQPYRVVVLSFELLNAPATVCGPKLSTDLIKNQCVNFNFNGLTGTGVLTPSSKRFQPFQQFGRDVSDFTDSVRDPKTSEILDISPCSFGGVSVITPGTNASSEVAVLYQDVNCTDVSTAIHADQLTPAWRIYSTGNNVFQTQAGCLIGAEHVDTSYECDIPIGAGICASYHTVSLLRSTSQKSIVAYTMSLGADSSIAYSNNTIAIPTNFSISITTEVMPVSMAKTSVDCNMYICGDSTECANLLLQYGSFCTQLNRALSGIAAEQDRNTREVFAQVKQMYKTPTLKYFGGFNFSQILPDPLKPTKRSFIEDLLFNKVTLADAGFMKQYGECLGDINARDLICAQKFNGLTVLPPLLTDDMIAAYTAALVSGTATAGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKQIANQFNKAISQIQESLTTTSTALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQAAPHGVVFLHVTYVPSQERNFTTAPAICHEGKAYFPREGVFVFNGTSWFITQRNFFSPQIITTDNTFVSGNCDVVIGIINNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYVWLGFIAGLIAIVMVTILLCCMTSCCSCLKGACSCGSCCKFDEDDSEPVLKGVKLHYT'
        #Spike source
        #https://www.uniprot.org/uniprot/P59594.fasta
        CTCS=CompoundFeatures#SuperdrugNames
        Pfeatures= prot_feats_seq(Spike)#ACE2
        ###
        PTCS=np.array([Pfeatures for i in range(len(CTCS))])#Copy same feature of protein equal to number of unique compounds
        Superdrug_Labels=-1*(np.ones(len(CTCS)))
        Filename='Spike'
        n=len(PTCS)
        sorted_indexTest,sorted_scoreTest,sorted_LabelsTest=PredictscorefromPair(Ptr, Ctr,Pscaler,Cscaler,PTCS,CTCS,n,Superdrug_Labels)
        Superdrug_topNames=SuperdrugNames[sorted_indexTest]
        ##Writing data for everyfold seprately
        DataWriteExcelNewsheet(Filename,NegtiveRatio,n,f,Superdrug_topNames,sorted_scoreTest)
        Ranks=np.array([np.array (c) for c in range(1,len(Superdrug_topNames)+1)])
        RanksDict=dict (zip(Superdrug_topNames,Ranks))
        for key in RanksDict.keys():
            MergeDict.setdefault(key, []).append(RanksDict[key])
        ###
        PfeaturesACE2= prot_feats_seq(ACE2)
        ###
        PTCSACE2 =np.array([PfeaturesACE2 for i in range(len(CTCS))])#Copy same feature of protein equal to number of unique compounds
        Superdrug_Labels=-1*(np.ones(len(CTCS)))
        Filename='ACE2'
        n=len(PTCS)
        #PTCSACE2 = Pscaler.transform(PTCSACE2)
        sorted_indexTest_ACE2,sorted_scoreTest_ACE2,sorted_LabelsTest_ACE2=PredictscorefromPair(Ptr, Ctr,Pscaler,Cscaler,PTCSACE2,CTCS,n,Superdrug_Labels)
        Superdrug_topNames_ACE2=SuperdrugNames[sorted_indexTest_ACE2]
        DataWriteExcelNewsheet(Filename,NegtiveRatio,n,f,Superdrug_topNames_ACE2,sorted_scoreTest_ACE2)
        Ranks_ACE2=np.array([np.array (c) for c in range(1,len(Superdrug_topNames)+1)])
        RanksDict_ACE2=dict (zip(Superdrug_topNames_ACE2,Ranks_ACE2))
        for key in RanksDict_ACE2.keys():
            MergeDict_ACE2.setdefault(key, []).append(RanksDict_ACE2[key])
        #1/0
        #DataWriteExcelNewsheet(Filename,NegtiveRatio,n,f,Superdrug_topNames,sorted_scoreTest)
        #ACE2 source
        #https://www.uniprot.org/uniprot/Q9BYF1#sequences
        #TranmembraneP='MALNSGSPPAIGPYYENHGYQPENPYPAQPTVVPTVYEVHPAQYYPSPVPQYAPRVLTQASNPVVCTQPKSPSGTVCTSKTKKALCITLTLGTFLVGAALAAGLLWKFMGSKCSNSGIECDSSGTCINPSNWCDGVSHCPGGEDENRCVRLYGPNFILQVYSSQRKSWHPVCQDDWNENYGRAACRDMGYKNNFYSSQGIVDDSGSTSFMKLNTSAGNVDIYKKLYHSDACSSKAVVSLRCIACGVNLNSSRQSRIVGGESALPGAWPWQVSLHVQNVHVCGGSIITPEWIVTAAHCVEKPLNNPWHWTAFAGILRQSFMFYGAGYQVEKVISHPNYDSKTKNNDIALMKLQKPLTFNDLVKPVCLPNPGMMLQPEQLCWISGWGATEEKGKTSEVLNAAKVLLIETQRCNSRYVYDNLITPAMICAGFLQGNVDSCQGDSGGPLVTSKNNIWWLIGDTSWGSGCAKAYRPGVYGNVMVFTDWIYRQMRADG'
        #source
        #https://www.ncbi.nlm.nih.gov/protein/O15393.3?report=fasta
        ####
        #####Testing
        # Lmj_eIF4E4 (Binding residues in yellow) (Binding domain underlined)
        Lmj_eIF4E4  = 'MSTPLDVRAAEYSPSFAVTMKKTVAAAPPKSPAPAKSKISVTRTGVNTTYPMPPPMPEKNYAPFFAEGCQTIAASKASMPPVQPASPLPPMHSAPPTASVVSNSIPPSSPATAPGERSPAVAARSVPTRFSPATVPRHHMNPNATEFMPGRRNGPDGGLEALPTSTADMELAKTPAGAAAAAVHAPSLPGAVRRSLQNSPIIQPSRLSVKSASEIEAISKNSALNAAAAAYVPQRTLARVVLTQPSPLALAPSEDPAKNNIEMMLDDLWCLFYLPTTLGENIKEEDYNPTLVFRVDSILTFWRVVNNIAAPSELQLSTLYLFRDGIDPKWEDPANRDGGIVKVKATAAQVDEAWELLLCRTIGDSWSPSVRETVNGVVLKVRERAYWLELWVTKNSSALQKDLAELWHPILGASFATTYLTHAMMQERSHAAAALAAEKQKKNRRRY'
        ###
        # Lmj_PABP1
        Lmj_PABP1= 'MAAAVQEAAAPVAHQPQMDKPMQIASIYVGDLDATINEPQLVELFKPFGTILNVRVCRDIITQRSLGYGYVNFDNHDSAEKAIESMNFKRVGDKCVRLMWQQRDPALRYSGNGNVFVKNLEKDVDSKSLHDIFTKFGSILSCKVMQDEEGKSRGYGFVHFKDETSAKDAIVKMNGAADHASEDKKALYVANFIRRNARLAALVANFTNVYIKQVLPTVNKDVIEKFFAKFGGITSAAACKDKSGRVFAFCNFEKHDDAVKAVEAMHDHHIDGITAPGEKLYVQRAQPRSERLIALRQKYMQHQALGNNLYVRNFDPEFTGADLLELFKEYGEVKSCRVMVSESGVSRGFGFVSFSNADEANAALREMNGRMLNGKPLIVNIAQRRDQRYTMLRLQFQQRLQMMMRQMHQPMPFVGSQGRPMRGRGGRQQLGGRAQGHPMPMPSPQQPQAPAQPQGFATPSAVGFVQATPKHSPGDVPETPPLPPITPQELESMSPQEQRAALGDRLFLKVYEIAPELAPKITGMFLEMKPKEAYELLNDQKRLEERVTEALCVLKAHQTA'
        CTCS=CompoundFeatures#SuperdrugNames
        Pfeatures= prot_feats_seq(Lmj_eIF4E4 )#ACE2
        ###
        PTCS=np.array([Pfeatures for i in range(len(CTCS))])#Copy same feature of protein equal to number of unique compounds
        Superdrug_Labels=-1*(np.ones(len(CTCS)))
        Filename='Lmj_eIF4E4 Top50'
        n=len(PTCS)
        sorted_indexTest,sorted_scoreTest,sorted_LabelsTest=PredictscorefromPair(Ptr, Ctr,Pscaler,Cscaler,PTCS,CTCS,n,Superdrug_Labels)
        Superdrug_topNames=SuperdrugNames[sorted_indexTest]
        ##Writing data for everyfold seprately
        DataWriteExcelNewsheet(Filename,NegtiveRatio,n,f,Superdrug_topNames,sorted_scoreTest)
        Ranks=np.array([np.array (c) for c in range(1,len(Superdrug_topNames)+1)])
        RanksDict=dict (zip(Superdrug_topNames,Ranks))
        for key in RanksDict.keys():
            MergeDict.setdefault(key, []).append(RanksDict[key])
        ###
        PfeaturesLmj_PABP1= prot_feats_seq(Lmj_PABP1)
        ###
        PTCSLmj_PABP1 =np.array([PfeaturesLmj_PABP1 for i in range(len(CTCS))])#Copy same feature of protein equal to number of unique compounds
        Superdrug_Labels=-1*(np.ones(len(CTCS)))
        Filename='Lmj_PABP1'
        n=len(PTCS)
        #PTCSACE2 = Pscaler.transform(PTCSACE2)
        sorted_indexTest_Lmj_PABP1,sorted_scoreTest_Lmj_PABP1,sorted_LabelsTest_Lmj_PABP1=PredictscorefromPair(Ptr, Ctr,Pscaler,Cscaler,PTCSLmj_PABP1,CTCS,n,Superdrug_Labels)
        Superdrug_topNames_Lmj_PABP1=SuperdrugNames[sorted_indexTest_Lmj_PABP1]
        DataWriteExcelNewsheet(Filename,NegtiveRatio,n,f,Superdrug_topNames_Lmj_PABP1,sorted_scoreTest_Lmj_PABP1)
        Ranks_Lmj_PABP1=np.array([np.array (c) for c in range(1,len(Superdrug_topNames)+1)])
        RanksDict_Lmj_PABP1=dict (zip(Superdrug_topNames_Lmj_PABP1,Ranks_Lmj_PABP1))
        for key in RanksDict_Lmj_PABP1.keys():
            MergeDict_Lmj_PABP1.setdefault(key, []).append(RanksDict_Lmj_PABP1[key])
        ####PROTAC

        ######
        ACE2='MSSSSWLLLSLVAVTAAQSTIEEQAKTFLDKFNHEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTLAQMYPLQEIQNLTVKLQLQALQQNGSSVLSEDKSKRLNTILNTMSTIYSTGKVCNPDNPQECLLLEPGLNEIMANSLDYNERLWAWESWRSEVGKQLRPLYEEYVVLKNEMARANHYEDYGDYWRGDYEVNGVDGYDYSRGQLIEDVEHTFEEIKPLYEHLHAYVRAKLMNAYPSYISPIGCLPAHLLGDMWGRFWTNLYSLTVPFGQKPNIDVTDAMVDQAWDAQRIFKEAEKFFVSVGLPNMTQGFWENSMLTDPGNVQKAVCHPTAWDLGKGDFRILMCTKVTMDDFLTAHHEMGHIQYDMAYAAQPFLLRNGANEGFHEAVGEIMSLSAATPKHLKSIGLLSPDFQEDNETEINFLLKQALTIVGTLPFTYMLEKWRWMVFKGEIPKDQWMKKWWEMKREIVGVVEPVPHDETYCDPASLFHVSNDYSFIRYYTRTLYQFQFQEALCQAAKHEGPLHKCDISNSTEAGQKLFNMLRLGKSEPWTLALENVVGAKNMNVRPLLNYFEPLFTWLKDQNKNSFVGWSTDWSPYADQSIKVRISLKSALGDKAYEWNDNEMYLFRSSVAYAMRQYFLKVKNQMILFGEEDVRVANLKPRISFNFFVTAPKNVSDIIPRTEVEKAIRMSRSRINDAFRLNDNSLEFLGIQPTLGPPNQPPVSIWLIVFGVVMGVIVVGIVILIFTGIRDRKKKNKARSGENPYASIDISKGENNPGFQNTDDVQTSF'
        #ACE2 source
        #https://www.uniprot.org/uniprot/Q9BYF1#sequences
        ###
        Spike='MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEIFRSDTLYLTQDLFLPFYSNVTGFHTINHTFGNPVIPFKDGIYFAATEKSNVVRGWVFGSTMNNKSQSVIIINNSTNVVIRACNFELCDNPFFAVSKPMGTQTHTMIFDNAFNCTFEYISDAFSLDVSEKSGNFKHLREFVFKNKDGFLYVYKGYQPIDVVRDLPSGFNTLKPIFKLPLGINITNFRAILTAFSPAQDIWGTSAAAYFVGYLKPTTFMLKYDENGTITDAVDCSQNPLAELKCSVKSFEIDKGIYQTSNFRVVPSGDVVRFPNITNLCPFGEVFNATKFPSVYAWERKKISNCVADYSVLYNSTFFSTFKCYGVSATKLNDLCFSNVYADSFVVKGDDVRQIAPGQTGVIADYNYKLPDDFMGCVLAWNTRNIDATSTGNYNYKYRYLRHGKLRPFERDISNVPFSPDGKPCTPPALNCYWPLNDYGFYTTTGIGYQPYRVVVLSFELLNAPATVCGPKLSTDLIKNQCVNFNFNGLTGTGVLTPSSKRFQPFQQFGRDVSDFTDSVRDPKTSEILDISPCSFGGVSVITPGTNASSEVAVLYQDVNCTDVSTAIHADQLTPAWRIYSTGNNVFQTQAGCLIGAEHVDTSYECDIPIGAGICASYHTVSLLRSTSQKSIVAYTMSLGADSSIAYSNNTIAIPTNFSISITTEVMPVSMAKTSVDCNMYICGDSTECANLLLQYGSFCTQLNRALSGIAAEQDRNTREVFAQVKQMYKTPTLKYFGGFNFSQILPDPLKPTKRSFIEDLLFNKVTLADAGFMKQYGECLGDINARDLICAQKFNGLTVLPPLLTDDMIAAYTAALVSGTATAGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKQIANQFNKAISQIQESLTTTSTALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQAAPHGVVFLHVTYVPSQERNFTTAPAICHEGKAYFPREGVFVFNGTSWFITQRNFFSPQIITTDNTFVSGNCDVVIGIINNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYVWLGFIAGLIAIVMVTILLCCMTSCCSCLKGACSCGSCCKFDEDDSEPVLKGVKLHYT'
        #Spike source
        #https://www.uniprot.org/uniprot/P59594.fasta
        TranmembraneP='MALNSGSPPAIGPYYENHGYQPENPYPAQPTVVPTVYEVHPAQYYPSPVPQYAPRVLTQASNPVVCTQPKSPSGTVCTSKTKKALCITLTLGTFLVGAALAAGLLWKFMGSKCSNSGIECDSSGTCINPSNWCDGVSHCPGGEDENRCVRLYGPNFILQVYSSQRKSWHPVCQDDWNENYGRAACRDMGYKNNFYSSQGIVDDSGSTSFMKLNTSAGNVDIYKKLYHSDACSSKAVVSLRCIACGVNLNSSRQSRIVGGESALPGAWPWQVSLHVQNVHVCGGSIITPEWIVTAAHCVEKPLNNPWHWTAFAGILRQSFMFYGAGYQVEKVISHPNYDSKTKNNDIALMKLQKPLTFNDLVKPVCLPNPGMMLQPEQLCWISGWGATEEKGKTSEVLNAAKVLLIETQRCNSRYVYDNLITPAMICAGFLQGNVDSCQGDSGGPLVTSKNNIWWLIGDTSWGSGCAKAYRPGVYGNVMVFTDWIYRQMRADG'
        #source
        #https://www.ncbi.nlm.nih.gov/protein/O15393.3?report=fasta
        n=50
        #SpikeNames,Spikescores=PredictTopNscores(Ptr, Ctr,Spike,n)
        TranmembranePnames,TranmembranePscores=PredictTopNscores(Ptr, Ctr,TranmembraneP,n)
        ACE2Names,ACE2scores=PredictTopNscores(Ptr, Ctr,ACE2,n)
        #DataWriteExcel(NegtiveRatio,n,f,ACE2Names,ACE2scores,SpikeNames,Spikescores) 
        DataWriteExcel(NegtiveRatio,n,f,ACE2Names,ACE2scores,TranmembranePnames,TranmembranePscores)
        #####
        Filename='Lmj_eIF4E4_Lmj_PABP1'
        n=50
        #SpikeNames,Spikescores=PredictTopNscores(Ptr, Ctr,Spike,n)
        Lmj_eIF4E4names,Lmj_eIF4E4scores=PredictTopNscores(Ptr, Ctr,Lmj_eIF4E4,n)
        Lmj_PABP1Names,Lmj_PABP1scores=PredictTopNscores(Ptr, Ctr,Lmj_PABP1,n)
        #DataWriteExcel(NegtiveRatio,n,f,ACE2Names,ACE2scores,SpikeNames,Spikescores) 
        DataWriteExcel(Filename,NegtiveRatio,n,f,Lmj_eIF4E4names,Lmj_eIF4E4scores,Lmj_PABP1Names,Lmj_PABP1scores)
        ###
        """
    fpr, tpr, thresholds = roc_curve(Yo, Z)  
    auc = roc_auc_score(Yo, Z)
    #####
    plt.plot(fpr,tpr);plt.title(auc);plt.xlabel('FPR');plt.ylabel('TPR');plt.show()
    print("Final average over 5folds",np.average(AUC_ROC_final).round(4),'±',np.std( AUC_ROC_final).round(4),np.average(Precision_final).round(4),'±',np.std( Precision_final).round(4),np.average(Recall_final).round(4),'±',np.std( Recall_final).round(4),np.average(Avg_P_final).round(4),'±',np.std( Avg_P_final).round(4))
    print("Alpha_threshold=",Alpha_threshold,"NegtiveRatio=",NegtiveRatio)#,"AUC=",auc,"Percision=",precision,"Recall=",recall,"average_precision_score",average_P_score)
    1/0
    #####Average rank
    """
    AverageRankMerge=np.array([(c,np.average(MergeDict[c]).round(2)) for c in MergeDict])
    AverageRankMergeDict=dict (AverageRankMerge)
    ###ACE2
    AverageRankMerge_ACE2=np.array([(c,np.average(MergeDict_ACE2[c]).round(2)) for c in MergeDict_ACE2])
    AverageRankMergeDict_ACE2=dict (AverageRankMerge_ACE2)
    """
    ##Median
    AverageRankMerge=np.array([(c,np.median(MergeDict[c]).round(2)) for c in MergeDict])
    AverageRankMergeDict=dict (AverageRankMerge)
    ###ACE2
    AverageRankMerge_ACE2=np.array([(c,np.median(MergeDict_ACE2[c]).round(2)) for c in MergeDict_ACE2])
    AverageRankMergeDict_ACE2=dict (AverageRankMerge_ACE2)
    ###Lmj_PABP1
    """
    AverageRankMerge_Lmj_PABP1=np.array([(c,np.average(MergeDict_Lmj_PABP1[c]).round(2)) for c in MergeDict_Lmj_PABP1])
    AverageRankMergeDict_Lmj_PABP1=dict (AverageRankMerge_Lmj_PABP1)
    """
    ####
    import xlsxwriter
    path='/content/drive/MyDrive/CPI_Data/'
    Filename=path+'MedianResultsNegativeRatio7.xlsx'
    workbook = xlsxwriter.Workbook(Filename)#path+Name+'ResultsNegativeRatio'+Ratio+'Fold'+str (fold)+'.xlsx')
    Proteinname1='Spike'
    Proteinname2='ACE2'
    worksheet = workbook.add_worksheet()
    col = 0;row = 0;
    worksheet.write(row, col,Proteinname2+' AverageRank')#_ACE2
    worksheet.write(row, col+1, Proteinname2+'Names')
    ###
    worksheet.write(row, col+3, Proteinname1+'AverageRank')
    worksheet.write(row, col+4, Proteinname1+'Names')
    ####
    for i,key in zip(range(len(list (AverageRankMergeDict.keys()))),list (AverageRankMergeDict.keys())):
      row = i+1
      #print("i",i)
      #####
      #worksheet.write(row, col,float (AverageRankMergeDict_Lmj_PABP1[key]))
      worksheet.write(row, col,float (AverageRankMergeDict_ACE2[key]))
      worksheet.write(row, col+1, key)
      worksheet.write(row, col+3,float (AverageRankMergeDict[key]))
      worksheet.write(row, col+4, key)
      #####
    workbook.close()
  

    1/0
    #####2p2iTest
    P_test,C_test,Y_test=Features_Predictor()
    P_test,C_test = Pscaler.transform(P_test), Cscaler.transform(C_test)
    
    Kp = kernel(P_test,Ptr)
    Kc = kernel(C_test,Ctr)
    Ktt_test = (Kp+Kc)**2# (Kp**2+Kc**2+2*Kp*Kc)
    
    z_test = clf.decision_function(Ktt_test)
    auc_test = roc_auc_score(Y_test, z_test)
    yp_test=clf.predict(Ktt_test)
    precision_test = precision_score(Y_test, yp_test)
    recall_test = recall_score(Y_test, yp_test)
    average_precision_score_test=average_precision_score(Y_test, z_test)
    print("AUC_test=",auc_test,"Percision_test=",precision_test,"Recall_test=",recall_test,"average_precision_score_test",average_precision_score_test)
    1/0
#%% Training on all 
    
    # Ptr,Ctr = P,C
    # y_train = Y
    # Pscaler = StandardScaler().fit(Ptr)
    # Cscaler = StandardScaler().fit(Ctr)
    # Ptr,Ctr = Pscaler.transform(Ptr), Cscaler.transform(Ctr)
    
    # Kp = kernel(Ptr)
    # Kc = kernel(Ctr)
    # Ktr = (Kp+Kc)**2# (Kp**2+Kc**2+2*Kp*Kc)
    
    # clf = SVC(C = 100.0, kernel = 'precomputed',class_weight='balanced')
    # clf.fit(Ktr,y_train)
    
#%% Testing 
    # Lmj_eIF4E4 (Binding residues in yellow) (Binding domain underlined)
    s = 'MSTPLDVRAAEYSPSFAVTMKKTVAAAPPKSPAPAKSKISVTRTGVNTTYPMPPPMPEKNYAPFFAEGCQTIAASKASMPPVQPASPLPPMHSAPPTASVVSNSIPPSSPATAPGERSPAVAARSVPTRFSPATVPRHHMNPNATEFMPGRRNGPDGGLEALPTSTADMELAKTPAGAAAAAVHAPSLPGAVRRSLQNSPIIQPSRLSVKSASEIEAISKNSALNAAAAAYVPQRTLARVVLTQPSPLALAPSEDPAKNNIEMMLDDLWCLFYLPTTLGENIKEEDYNPTLVFRVDSILTFWRVVNNIAAPSELQLSTLYLFRDGIDPKWEDPANRDGGIVKVKATAAQVDEAWELLLCRTIGDSWSPSVRETVNGVVLKVRERAYWLELWVTKNSSALQKDLAELWHPILGASFATTYLTHAMMQERSHAAAALAAEKQKKNRRRY'
    #s = 'MNPNATEFMPGRRNGPDGGLEALPTSTADMELAKTPAGAAAAAVHAPSLPGAVRRSLQNSPIIQPSRLSVKSASEIEAISKNSALN'
    # Lmj_PABP1
    s = 'MAAAVQEAAAPVAHQPQMDKPMQIASIYVGDLDATINEPQLVELFKPFGTILNVRVCRDIITQRSLGYGYVNFDNHDSAEKAIESMNFKRVGDKCVRLMWQQRDPALRYSGNGNVFVKNLEKDVDSKSLHDIFTKFGSILSCKVMQDEEGKSRGYGFVHFKDETSAKDAIVKMNGAADHASEDKKALYVANFIRRNARLAALVANFTNVYIKQVLPTVNKDVIEKFFAKFGGITSAAACKDKSGRVFAFCNFEKHDDAVKAVEAMHDHHIDGITAPGEKLYVQRAQPRSERLIALRQKYMQHQALGNNLYVRNFDPEFTGADLLELFKEYGEVKSCRVMVSESGVSRGFGFVSFSNADEANAALREMNGRMLNGKPLIVNIAQRRDQRYTMLRLQFQQRLQMMMRQMHQPMPFVGSQGRPMRGRGGRQQLGGRAQGHPMPMPSPQQPQAPAQPQGFATPSAVGFVQATPKHSPGDVPETPPLPPITPQELESMSPQEQRAALGDRLFLKVYEIAPELAPKITGMFLEMKPKEAYELLNDQKRLEERVTEALCVLKAHQTA'
    #s = 'LPPITPQELESMSPQEQRAALGDRLFLKVYEIAPELAPKITGMFLEMKPKEAYELLNDQKRLEERVTEALCVLKAHQTA'
    #s = 'SWISSCHEESE'#'MADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTEAELQDMINEVDADGNGTIDFPEFLTMMARKMKDTDSEEEIREAFRVFDKDGNGYISAAELRHVMTNLGEKLTDEEVDEMIREADIDGDGQVNYEEFVQMMTAK'
    #s = 'MFRQEQPLAEGSFAPMGSLQPDAGNASWNGTEAPGGGARATPYSLQVTLTLVCLAGLLMLLTVFGNVLVIIAVFTSRALKAPQNLFLVSLASADILVATLVIPFSLANEVMGYWYFGKAWCEIYLALDVLFCTSSIVHLCAISLDRYWSITQAIEYNLKRTPRRIKAIIITVWVISAVISFPPLISIEKKGGGGGPQPAEPRCEINDQKWYVISSCIGSFFAPCLIMILVYVRIYQIAKRRTRVPPSRRGPDAVAAPPGGTERRPNGLGPERSAGPGGAEAEPLPTQLNGAPGEPAPAGPRDTDALDLEESSSSDHAERPPGPRRPERGPRGKGKARASQVKPGDSLPRRGPGATGIGTPAAGPGEERVGAAKASRWRGRQNREKRFTFVLAVVIGVFVVCWFPFFFTYTLTAVGCSVPRTLFKFFFWFGYCNSSLNPVIYTIFNHDFRRAFKKILCRGDRKRIV'
    #s = 'MSLPNSSCLLEDKMCEGNKTTMASPQLMPLVVVLSTICLVTVGLNLLVLYAVRSERKLHTVGNLYIVSLSVADLIVGAVVMPMNILYLLMSKWSLGRPLCLFWLSMDYVASTASIFSVFILCIDRYRSVQQPLRYLKYRTKTRASATILGAWFLSFLWVIPILGWNHFMQQTSVRREDKCETDFYDVTWFKVMTAIINFYLPTLLMLWFYAKIYKAVRQHCQHRELINRSLPSFSEIKLRPENPKGDAKKPGKESPWEVLKRKPKDAGGGSVLKSPSQTPKEMKSPVVFSQEDDREVDKLYCFPLDIVHMQAAAEGSSRDYVAVNRSHGQLKTDEQGLNTHGASEISEDQMLGDSQSFSRTDSDTTTETAPGKGKLRSGSNTGLDYIKFTWKRLRSHSRQYVSGLHMNRERKAAKQLGFIMAAFILCWIPYFIFFMVIAFCKNCCNEHLHMFTIWLGYINSTLNPLIYPLCNENFKKTFKRILHIRS'
    Cuseq = np.unique(Cseq)
    """
    pp = 'h1'#[]
    with open('../../../../'+pp+"_inactive.txt") as f:
        Cuseq = np.array(f.readlines())
    """
    xp = prot_feats_seq(s)
    Ptt = np.array([xp]*len(Cuseq))
    """
    Cseq = np.array(Cseq)
    Pseq = np.array(Pseq)
    Cuseq=Cseq[test_index]
    Puseq=Pseq[test_index]        
    Ptt = np.array([prot_feats_seq(s) for s in Puseq])
    """
    Ctt = np.array([getFP(c) for c in Cuseq])    
    
    Ptt,Ctt = Pscaler.transform(Ptt), Cscaler.transform(Ctt)
        
    Kp = kernel(Ptt,Ptr)
    Kc = kernel(Ctt,Ctr)
    Ktt = (Kp+Kc)**2# (Kp**2+Kc**2+2*Kp*Kc)
    
    z = clf.decision_function(Ktt)
    """
    yy = Y[test_index]
    fpr, tpr, thresholds = roc_curve(yy, z)  
    auc = roc_auc_score(yy, z)
    plt.plot(fpr,tpr);plt.title(auc);plt.xlabel('FPR');plt.ylabel('TPR');plt.show()
    """

    idx = np.argsort(-z)    
    print(Cuseq[idx[:3]])
    M = [Chem.MolFromSmiles(Cuseq[i]) for i in idx[:10]]
    # for i in idx[:10]:
    #     m = Chem.MolFromSmiles(Cuseq[i])
    #     SVG(moltosvg(m))
#%%
    zpos=list(zpos);zneg=list(zneg)
    yy=[1]*len(zpos)+[-1]*len(zneg)
    zz = zpos+zneg
    fpr, tpr, thresholds = roc_curve(yy, zz)  
    auc = roc_auc_score(yy, zz)
    precision = precision_score(yy, zz)
    recall = recall_score(yy, zz)
    average_precision_score=average_precision_score(yy, zz)
    plt.plot(fpr,tpr);plt.title(auc);plt.xlabel('FPR');plt.ylabel('TPR');plt.show()
    print("AUC=",auc,"Percision=",precision,"Recall=",recall,"average_precision_score",average_precision_score)
